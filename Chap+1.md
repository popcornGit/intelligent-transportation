# Chap 1

## 1. 智慧交通各类场景算法划分

### 1.1 指挥交通的场景划分

#### 场景主要划分为: 十字路口, 交通卡口, 交通出入口, 停车场等

####  

#### 交通行业主要对交通场景内的行人, 机动车, 非机动车进行识别分析

##### 行人识别分析

###### 姿态, 方向, 外观, 以及基于行人的交通事件识别分析

###### 例如, 行人闯红灯等

##### 机动车识别分析

###### 外形,颜色, 车灯, 车窗, 驾驶员安全事件分析

###### 例如, 是否在打电话, 是否系安全带

###### 车牌, 车辆方向和基于机动车的交通事件识别分析

###### 例如, 超速检测, 违停判定等

##### 非机动车识别分析

###### 细分类别识别, 运动状态识别, 驾驶员安全事件分析

###### 例如, 是否带安全头盔

###### 基于非机动车的交通事件识别分析

###### 例如非机动车闯红灯等

### 1.2 智慧交通的算法划分

#### 应用场景

##### AI算法功能

###### AI算法模型

#### 上面三者的有机结合, 形成了面对不同需求的整体算法解决方案

####  

#### 车牌识别功能=车辆检测+车牌检测+车牌OCR识别+业务功能判断

#### 行人识别功能=行人检测+人脸识别+行人重识别

#### 车辆属性识别功能=车辆检测+车标识别+车系识别+驾驶员行为识别

#### 交通事件检测功能

##### 更加复杂, 例如行人闯红灯, 车辆闯红灯, 机动车超速, 超时停车, 机动车违停等

##### =

###### 大量交通规则作为约束

###### 检测机动车, 行人, 非机动车

###### 准确感知当前的背景环境条件

####### 例如, 检测交通指示牌, 检测交通道路指示线

### 1.3 智慧交通+AI安全功能

#### 车辆识别, 车辆属性识别, 交通事件检测, 交通执法判定, 行人识别等是智慧交通中的复合任务

#### 复合任务的流程中, 可能存在AI安全的风险

#### AI安全风险

##### 例如对交通指示牌进行对抗攻击

###### 风格迁移攻击

###### 导致对交通指示牌的误判

###### 可能引发严重交通连锁后果

##### 例如对行人检测进行攻击

###### 对抗贴纸攻击

###### 对行人检测模型产生较大的影响

###### 无法对行人做出准确的检测

#### AI安全防御策略

##### 对抗样本检测

##### 黑盒攻击防御

##### 白盒攻击防御

## 2. 智慧交通的落地部署架构方式

### 2.1 AI项目通用的开发交付流程

####  

##### 1. 明确场景&用户需求&获取数据

###### 业务场景定义机器学习问题

###### 用户需求指明了切入点和优化方向

####### 例如, 车辆属性识别

######## 首先要确定场景

######### 十字路口

######### 卡口

######### 出入口

######### 停车场

######## 用户需求

######### 哪些车辆属性是用户的核心需求 

######### 场景中的亮度

######### 数据源（摄像头）获取的图像的清晰程度

######### 是否存在大角度的目标

######### 场景中的流量复杂程度

######## 数据

######### 现场采集数据

######### 数据标注

######### 数据清洗校验

###### 数据侧不断去逼近这个机器学习问题的真实数据分布

##### 2. 算法训练&模型部署

###### 训练

####### 完成上面第一步

####### 选用合适的算法模型

####### 进行训练和优化

###### 部署

####### 模型转换

####### 模型量化

####### 模型与平台适配等工作

##### 3. 多部门协作&多模板集成

###### 多模块的算法功能与配套功能进行结合

###### 形成完整的解决方案

### 2.2 AI项目通用的部署形式

####  

##### 1. 线上部署

###### 网络调用

####### 响应速度是非常重要的考虑因素

####### 例如, 一个有效的部署逻辑是：TensorFlow_Serving + Docker + Web.

#######  

######## 处理中心

######### 利用flask, tornado, django搭建http服务

######### 将客户端输入传给模型

######### 将模型输出结果打包返回

######## Serving端

######### TensorFlow_Serving能够把算法模型挂在服务器后台

######### 客户端发动请求，会把模型运算后的结果打包返回

###### Offline模型

####### 一般在精细化场景中使用

####### 例如,对交通事件或违规事件进行复核

####### 这个阶段更注重模型准确度与可靠性

##### 2. 嵌入式部署

###### 硬件/芯片部署

####### 步骤

######## 算法模型训练

######## 图片量化校准

######## 转换工具转换模型

######## 模型精度测试

####### 带GPU的嵌入式端，也就是GPU盒子

######## 使用CUDA可以加速的框架就能较好的部署

######## 最为方便的一种硬件部署方式

####### 芯片

######## 一般都是基于ARM架构

######## 基于CPU完成深度神经网络推断

######### 最基础

######### 最可靠

###### 离线app

####### 主要在手机端应用

####### 使用一些专门的轻量级框架会比较适合

##### 3. Docker部署

###### 公司不具备完整的算法上下游链路时

###### 只能作为算法模型API提供方

###### 通过配置相应的docker镜像，交付给目标客户

###### 客户自己调取相应的算法接口，从而完成业务流程

## 3. 边缘设备的行业场景应用

### AI端侧设备

#### 组成

##### 主要由ARM架构的CPU

##### GPU/TPU/NPU等协处理器

##### 工具链

##### 外围接口

#####  整体功耗

### 必备知识

#### 硬件性能评估

#### 模型转换与验证

#### 硬件高层API接口的开发与使用

### 进阶知识

#### 视频编解码

#### 模型推理加速

#### Opencv

#### FFmpeg

#### Tensor RT

#### 工具链开发
